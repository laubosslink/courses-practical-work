Le professeur David Albert Huffman (9 aout 1925 - 7 octobre 1999) fut un pionnier dans le domaine de l'informatique. Durant toute sa vie, Huffman apporta des contributions importantes a l'etude des machines a etats finis. Mais Huffman est principalement connu pour l'invention du codage de Huffman utilise dans presque toutes les applications qui impliquent la compression et la transmission de donnees digitales comme les fax, les modems, les reseaux informatiques et la television a haute definition.

Ne le 9 aout 1925 en Ohio, Huffman obtint sa licence en ingenierie electrique de l'universite de l'Ohio a l'age de 18 ans. Puis il travailla pour la Marine militaire des etats-Unis en tant qu'officier charge de la maintenance des radars a bord d'un destroyer 
qui detruisait les mines dans les mers du Japon et de la Chine apres la Seconde Guerre mondiale. Il obtint ensuite son master a l'universite de l'Ohio et son doctorat au MIT en 1953. 
En 1967, il alla a l'universite de Californie a Santa Cruz en tant que membre de la faculte du departement d'informatique. Il joua un role majeur dans le developpement des programmes academiques du departement et dans le recrutement des etudiants de la faculte, qu'il presida de 1970 a 1973. Il se retira en 1994 mais resta actif en tant que professeur, enseignant la theorie de l'information et l'analyse des signaux. 
Huffman contribua beaucoup au developpement de differents domaines, notamment dans la theorie de l'information et du codage, ou il a ete un pionnier dont les decouvertes sont a la base des systemes de compression de fichiers informatiques dans toutes les machines de nos jours. Il a aussi etudie les signaux pour les radars et les applications en communication, et des procedures pour la synchronisation logique des circuits. Comme supplement a son travail sur les proprietes mathematiques de la courbure nulle des surfaces, Huffman a aussi developpe une technique pour plier du papier dans des formes inhabituelles. Il mourut a l'age de 74 ans apres un combat de dix mois contre le cancer.

Ce que Huffman a accompli lui a valu de nombreuses recompenses. Il recut la Medaille Richard W. Hamming 1999 de l'Institut des ingenieurs electriciens et electronicien (IEEE) en reconnaissance de ses contributions dans l'information scientifique. Il recut egalement la Medaille Louis E. Levy de l'institut Franklin pour sa these de doctorat sur les circuits a switch sequentiels, un Distinguished Alumnus Award de l'universite de l'Ohio, et le W. Wallace McDowell Award.

Le codage de Huffman est un algorithme de compression de donnees sans perte elabore par David Albert Huffman, lors de sa these de doctorat au MIT. L'algorithme a ete publie en 1952 dans l'article A Method for the Construction of Minimum-Redundancy Codes, dans les Proceedings of the Institute of Radio Engineers. Le codage de Huffman utilise un code a longueur variable pour representer un symbole de la source (par exemple un caractere dans un fichier). Le code est determine a partir d'une estimation des probabilites d'apparition des symboles de source, un code court etant associe aux symboles de source les plus frequents. Les codes de Huffman sont des codes optimaux, au sens de la plus courte longueur.
Un code de Huffman est optimal pour un codage par symbole, et une distribution de probabilite connue. Il ne permet cependant pas d'obtenir les meilleurs ratios de compression. Des methodes plus complexes realisant une modelisation probabiliste de la source et tirant profit de cette redondance supplementaire permet d'ameliorer les performances de compression de cet algorithme (voir LZ77, prediction par reconnaissance partielle, ponderation de contextes).

Le principe du codage de Huffman repose sur la creation d'un arbre compose de noeuds. Supposons que la phrase a coder est 'wikipedia'. On recherche tout d'abord le nombre d'occurrences de chaque caractere (ici les caracteres 'a', 'd', 'e', 'k', 'p' et 'w' sont representes chacun une fois et le caractere 'i' trois fois). Chaque caractere constitue une des feuilles de l'arbre a laquelle on associe un poids valant son nombre d'occurrences. Puis l'arbre est cree suivant un principe simple : on associe a chaque fois les deux noeuds de plus faibles poids pour donner un noeud dont le poids equivaut a la somme des poids de ses fils jusqu'a n'en avoir plus qu'un, la racine. On associe ensuite par exemple le code 0 a la branche de gauche et le code 1 a la branche de droite. Pour obtenir le code binaire de chaque caractere, on remonte l'arbre a partir de la racine jusqu'aux feuilles en rajoutant a chaque fois au code un 0 ou un 1 selon la branche suivie. Il est en effet necessaire de partir de la racine pour obtenir les codes binaires car lors de la decompression, partir des feuilles entrainerait une confusion lors du decodage. Ici, pour coder 'Wikipedia', nous obtenons donc en binaire : 101 11 011 11 100 010 001 11 000, soit 24 bits au lieu de 63 (9 caracteres x 7 bits par caractere) en utilisant les codes ASCII (7 bits).
